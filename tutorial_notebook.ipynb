{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7ABC84LWnTT"
      },
      "source": [
        "# Different imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEcIlRwfWY4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ef5743-079b-4912-9195-539378677715"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMcYYu6XW8SJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b231e9f-368f-415d-cdb7-a01a5d7b8d85"
      },
      "source": [
        "# To go to the directory MyDrive directly (so that we don't type this path every second)\n",
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrEjjbaSXEwD"
      },
      "source": [
        "# To list what is inside the current directory\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7BjB7AW9qst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76472200-b927-472b-b727-c4a75907257a"
      },
      "source": [
        "# To install some dependencies\n",
        "!pip install tld"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tld\n",
            "  Downloading tld-0.12.6-py37-none-any.whl (412 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 31.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 412 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: tld\n",
            "Successfully installed tld-0.12.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mctOUaD1XKzf"
      },
      "source": [
        "# Different libraries import\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import bz2\n",
        "import json\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEU0iRykWj1n"
      },
      "source": [
        "# Tutorial "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKUy29h68N0J"
      },
      "source": [
        "## Extracting the domain names\n",
        "\n",
        "This is an example on how to extract domain names from a sample. To do that, we can use *tld* library. To install it:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK4YmTdA9wmY"
      },
      "source": [
        "Following function then gives domain name. It takes as an argument an URL and returns the domain name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdhreeYc8XEX"
      },
      "source": [
        "from tld import get_tld\n",
        "\n",
        "def get_domain(url):\n",
        "    res = get_tld(url, as_object=True)\n",
        "    return res.tld\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V67aCknDjgY"
      },
      "source": [
        "Now we will have to read the data. Each sample has property 'urls' which contains a list of links to the original articles containing the quotation. We will extract domain names for these links. Then, we will save a new file that contains samples with extracted domains. The new file will be saved in local storage in Colab but you can change path_to_out variable (optionally) if you want to save it directly to the drive. To generate a new file, run this cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHMv0FD0Eh_W"
      },
      "source": [
        "import bz2\n",
        "import json\n",
        "\n",
        "path_to_file = 'Quotebank/quotes-2020.json.bz2' \n",
        "path_to_out = 'Test.json.bz2'\n",
        "\n",
        "with bz2.open(path_to_file, 'rb') as s_file:\n",
        "    with bz2.open(path_to_out, 'wb') as d_file:\n",
        "        for instance in s_file:\n",
        "            instance = json.loads(instance) # loading a sample\n",
        "            urls = instance['urls'] # extracting list of links\n",
        "            domains = []\n",
        "            for url in urls:\n",
        "                tld = get_domain(url)\n",
        "                domains.append(tld)\n",
        "            instance['domains'] = domains # updating the sample with domain name\n",
        "            d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vOPobprkF2h"
      },
      "source": [
        "It should take around 25min for this cell to finish running and you will be able to see a file (*quotes-2020-domains.json.bz2*) in the file explorer on the left side once it is done.\n",
        "\n",
        "You are all set, good luck! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBf_Hjz0RfmK"
      },
      "source": [
        "# Milestone 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGTGEnFDVYkx"
      },
      "source": [
        "## Project description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L-_mAv9RMAC"
      },
      "source": [
        "First, one could try to associate a certain type of quote to the day(and even date) of the article. We do not have any pre-established pattern, but one could try to find one if any exists. Maybe there is a link between the nature of the quotation (political, good news/bad news, humoristic quote, and so on) and the day of the article. This can also be done with the consideration of historical event on the date of the publication. For example, there might be less joyful quotes in days during which tragic events happened."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ty5_qXLVqAk"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P3g9GobcyYQ"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEjr1RicVLxi"
      },
      "source": [
        "def retrieve_day(Date):\n",
        "  \"\"\" Retrieve the day from a date with format 'YYYY-MM-DD hh:mm:ss' where Y is years, M months, D day, h hours,\n",
        "      m minut and s seconds \n",
        "      Needs the following import :\n",
        "      from datetime import datetime\n",
        "      \"\"\"\n",
        "\n",
        "  try:                        \n",
        "    date = datetime.strptime(Date, '%Y-%m-%d %H:%M:%S') # Convert to a datetime object and check that the format is correct and the numbers are valid\n",
        "  except ValueError:\n",
        "    raise ValueError('The string \\'' + Date + '\\' does not match the format \\'YYYY-MM-DD hh:mm:ss\\'') from None # Customize the error message\n",
        "\n",
        "  if (date.year not in [2015, 2016, 2017, 2018, 2019, 2020]): # Check that the year is in the correct interval and that we do not have wrong data\n",
        "    raise ValueError(f'The year {date.year} that you provided is not between 2015 and 2020 (inclusive).')\n",
        "\n",
        "  weekday = datetime.isoweekday(date) # Obtain the weekday from 1 (monday) to 7 (sunday)\n",
        "\n",
        "  # There are no switch/case statement in Python <= 3.10...\n",
        "  if (weekday == 1):\n",
        "    return 'Monday'\n",
        "  elif (weekday == 2):\n",
        "    return 'Tuesday'\n",
        "  elif (weekday == 3):\n",
        "    return 'Wednesday'\n",
        "  elif (weekday == 4):\n",
        "    return 'Thursday'\n",
        "  elif (weekday == 5):\n",
        "    return 'Friday'\n",
        "  elif (weekday == 6):\n",
        "    return 'Saturday'\n",
        "  else:\n",
        "    return 'Sunday'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPQwJcIfXxWP"
      },
      "source": [
        "def create_frame(filename, N):\n",
        "  \"\"\" Creates a DataFrame with the N first rows of the file with filename \n",
        "      It is useful to load small portions and test things.            \"\"\"\n",
        "  list_of_dicts = []\n",
        "  with bz2.open(filename, 'rb') as s_file:\n",
        "      for i, instance in enumerate(s_file):\n",
        "        if (i>N-1):\n",
        "            break\n",
        "        instance = json.loads(instance) # loading a sample\n",
        "        list_of_dicts.append(instance)\n",
        "      \n",
        "  return pd.DataFrame(list_of_dicts)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxoFGb3Pc9MV"
      },
      "source": [
        "### Main code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwpDEXswXyLV"
      },
      "source": [
        "filename = 'Quotebank/quotes-2020.json.bz2' \n",
        "df = create_frame(filename, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPZx7VqqdDUR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "3369434f-489a-4bd1-b9c8-6b50f13ec2c1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quoteID</th>\n",
              "      <th>quotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>qids</th>\n",
              "      <th>date</th>\n",
              "      <th>numOccurrences</th>\n",
              "      <th>probas</th>\n",
              "      <th>urls</th>\n",
              "      <th>phase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-28-000082</td>\n",
              "      <td>[ D ] espite the efforts of the partners to cr...</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-01-28 08:04:05</td>\n",
              "      <td>1</td>\n",
              "      <td>[[None, 0.7272], [Prime Minister Netanyahu, 0....</td>\n",
              "      <td>[http://israelnationalnews.com/News/News.aspx/...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-16-000088</td>\n",
              "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
              "      <td>Sue Myrick</td>\n",
              "      <td>[Q367796]</td>\n",
              "      <td>2020-01-16 12:00:13</td>\n",
              "      <td>1</td>\n",
              "      <td>[[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...</td>\n",
              "      <td>[http://thehill.com/opinion/international/4782...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-02-10-000142</td>\n",
              "      <td>... He (Madhav) also disclosed that the illega...</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-02-10 23:45:54</td>\n",
              "      <td>1</td>\n",
              "      <td>[[None, 0.8926], [Prakash Rai, 0.1074]]</td>\n",
              "      <td>[https://indianexpress.com/article/business/ec...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-15-000053</td>\n",
              "      <td>... [ I ] f it gets to the floor,</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-02-15 14:12:51</td>\n",
              "      <td>2</td>\n",
              "      <td>[[None, 0.581], [Andy Harris, 0.4191]]</td>\n",
              "      <td>[https://patriotpost.us/opinion/68622-trump-bu...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-24-000168</td>\n",
              "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
              "      <td>Meghan King Edmonds</td>\n",
              "      <td>[Q20684375]</td>\n",
              "      <td>2020-01-24 20:37:09</td>\n",
              "      <td>4</td>\n",
              "      <td>[[Meghan King Edmonds, 0.5446], [None, 0.2705]...</td>\n",
              "      <td>[https://people.com/parents/meghan-king-edmond...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             quoteID  ... phase\n",
              "0  2020-01-28-000082  ...     E\n",
              "1  2020-01-16-000088  ...     E\n",
              "2  2020-02-10-000142  ...     E\n",
              "3  2020-02-15-000053  ...     E\n",
              "4  2020-01-24-000168  ...     E\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRLjWFibRuQ1",
        "outputId": "5332a0e8-72ac-4a94-f51d-007f3b953fd3"
      },
      "source": [
        "a = retrieve_day(df.loc[2, 'date'])\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monday\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aJiq7CklBMZ"
      },
      "source": [
        "# To add the weekday to every quote of the dataset. This will save a new dataset with the added day in the folder \"Quotebank_days\"\n",
        "# We create a new dataset to not alter the original in case of problems\n",
        "\n",
        "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
        "\n",
        "for year in tqdm(years):\n",
        "\n",
        "  path_to_file = f'Quotebank/quotes-{year}.json.bz2' \n",
        "  path_to_out = f'Quotebank_days/quotes-{year}.json.bz2'\n",
        "\n",
        "  with bz2.open(path_to_file, 'rb') as s_file:\n",
        "    with bz2.open(path_to_out, 'wb') as d_file:\n",
        "      for instance in tqdm(s_file):\n",
        "        instance = json.loads(instance) # loading a sample\n",
        "        day = retrieve_day(instance['date'])\n",
        "        instance['day'] = day\n",
        "        d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}